x
y
fit <- lm(y ~ x)
fit
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mean(x)
z= (8.58 - mean(x)) / sd(x)
z
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
0.4*1.5
1.5 / 0.4
library(MASS)
?shuttle
data(shuttle)
dim(shuttle)
str(shuttle)
logRegShuttle <- glm(use ~ wind, data=shuttle)
logRegShuttle <- glm(use ~ wind, data=shuttle, family="binomial")
summary(logRegShuttle)
exp(-0.03181)
exp(logRegShuttle$coeff)
logRegShuttle_magn <- glm(use ~ wind + magn, data=shuttle, family="binomial")
logRegShuttle_magn
exp(logRegShuttle_magn)
exp(logRegShuttle_magn$coeff)
unique(shuttle$magn)
1 - 0.9686888
fit <- glm(use ~ wind + as.factor(magn), family='binomial', shuttle)
fit
exp(fit$coeff)
install.packages("kernlab")
library(kernlab)
data(spam)
dim(spam)
str(spam)
head(spam, 3)
head(spam)
head(spam[spam$type=="nonspam"])
head(spam$your[spam$type=="nonspam"])
head([spam$type=="nonspam"])
head(spam[,spam$type=="nonspam"])
head(spam[spam$type=="nonspam",])
dim(spam)
length(spam$type)
prediction <- ifelse(spam$your > 0.5, "spam", "nonspam")
length(predictiom)
length(prediction)
head(prediction)
head(prediction["spam"])
table(prediction)
2580 / 4601
library(Hmisc)
library(Hmisc)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
length(training)
traing
training
length(training)
training[58]
str(training)
training[58, ]
training[57, ]
min(training$capitalAve)
max(training$capitalAve)
ave(training$capitalAve)
str(training)
test <- training[,-58]
str(test)
str(training)
library(caret); library(AppliedPredictiveModeling)
library(caret); library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
str(adData)
library(caret); library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
dim(training); dim(testing)
dim(adData)
251 + 82
251 / 333
3/4
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
dim(M)
str(M)
class(M)
str(training)
library(caret);data(faithful); set.seed(333)
dim(faithful)
names(faithful)
str(faithful)
inTrain <- createDataPartition(y=faithful$waiting,p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
install.packages("ISLR")
library(ISLR); library(ggplot2); library(caret);
data(Wage);
str(Wage)
Wage <- subset(Wage,select=-c(logwage))
str(Wage)
898+12
data(iris); library(ggplot2)
str(iris)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
str(segmentationOriginal)
names(segmentationOriginal)
str(segmentationOriginal$Case)
install.packages("pgmm")
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
str(olive)
olive = olive[,-1]
str(olive)
head(olive)
unique(olive$Area)
newdata = as.data.frame(t(colMeans(olive)))
str(newdata)
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
head(ozone)
install.packages("ElemStatLearn")
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
head(ozone)
head(ozone[7,])
str(ozone)
unique(ozone$ozone)
ozone <- ozone[order(ozone$ozone),]
str(ozone)
dim(ozone)
newdata=data.frame(ozone=1:155)
head(newdata)
tail(newdata)
min(ozone$ozone)
max(ozone$ozone)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
str(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
set.seed(125)
modFit <- train(Class ~ ., data = train, method = "rpart")
install.packages("rpart")
library(rpart)
modFit <- train(Class ~ ., data = train, method = "rpart")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret); library(rpart)
library(AppliedPredictiveModeling); library(caret); library(rpart)
data(segmentationOriginal)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
library(AppliedPredictiveModeling); library(caret); library(rpart)
data(segmentationOriginal)
set.seed(125)
modFit <- train(Class ~ ., data = train, method = "rpart")
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit <- train(Class ~ ., method="rpart", data=train)
modFit
str(tain)
str(train)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
install.packages(rattle)
install.packages("rattle")
library(rattle)
set.seed(125)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
modFit <- train(Class ~ ., data = train, method = "rpart")
install.packages("e1071")
library(e1071)
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = train)
library(pgmm)
data(olive)
str(olive)
olive = olive[,-1]
str(olive)
unique(olive$Area)
head(olive)
model = train(Area ~ ., method = 'rpart', data = olive)
fancyRpartPlot(model$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
newdata = as.data.frame(t(colMeans(olive)))
predict(model, newdata)
newdata
mean(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
model = train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = 'glm', family = 'binomial', data = trainSA)
trainPred = predict(model, trainSA)
testPred = predict(model, testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
trainMissClass = missClass(trainSA$chd, trainPred)
testMissClass = missClass(testSA$chd, testPred)
trainMissClass; testMissClass
library(ElemStatLearn)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
unique(vowel.train$y)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
model = train(y ~ ., method = 'rf', data = vowel.train, prox = TRUE)
library(caret)
model = train(y ~ ., method = 'rf', data = vowel.train, prox = TRUE)
library(randomForest)
model = train(y ~ ., method = 'rf', data = vowel.train, prox = TRUE)
model
vi = varImp(model$finalModel)
names(vi)
class(vi)
str(vi)
vi
names(vi[order(vi, decreasing = TRUE)]
)
names(vi[order(vi$Overall, decreasing = TRUE)]
)
vi <- vi[order(vi$Overall),]
vi
head vi
head(vi)
vi = varImp(model$finalModel)
str(vi)
vi
names(vi[order(vi, decreasing = TRUE)][1:10])
vi[with(vi, order(-Overall)),]
vi
vi$Overall <- order(vi$Overall)
vi
vi = varImp(model$finalModel)
str(vi)
vi
library(plyr)
arrange(vi,desc(Overall))
vi
vi = varImp(model$finalModel)
str(vi)
vi
vi = data.frame(var = 1:nrow(vi), imp = vi$Overall)
vi
vi[order(vi$imp),]
vi = varImp(model$finalModel)
vi = varImp(model$finalModel)
vi
vi[order(vi$Overall),]
str(vi)
getwd()
setwd("~/practicalMachineLearningCoursera")
pwd
dir()
getwd()
trainingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainingUrl, "pml-training.csv",  method="curl")
download.file(testingUrl, "pml-testing.csv",  method="curl")
dir()
trainingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainingUrl, "pml-training.csv",  method="curl")
download.file(testingUrl, "pml-testing.csv",  method="curl")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
dim(training); dim(testing)
trainingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainingUrl, "pml-training.csv",  method="curl")
download.file(testingUrl, "pml-testing.csv",  method="curl")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
dim(training); dim(testing)
sum(is.na(training))
train <- read.csv("pml-training.csv",na.strings=c("NA",""))
sum(is.na(train))
trainingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainingUrl, "pml-training.csv",  method="curl")
download.file(testingUrl, "pml-testing.csv",  method="curl")
training <- read.csv("pml-training.csv", na.strings=c("NA",""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA",""))
dim(training); dim(testing)
sum(is.na(training))
sum(is.na(testing))
str(training)
str(training$classe)
sum(is.na(training))
na_train = sapply(training, function(x) {sum(is.na(x))})
class(na_train)
length(na_train)
na_train[1]
head(na_train)
head(na_train)
head(na_train)
na_train
table(na_train)
columnNACounts <- colSums(is.na(training))
columnNACounts
badColumns <- columnNACounts >= 19000
badColumns
cleanTrainingdata <- training[!badColumns]
sum(is.na(cleanTrainingdata))
str(cleanTrainingdata)
dim(cleanTrainingdata)
str(badColumns)
varNACounts <- colSums(is.na(training))  # find out which variables have NAs
badVars <- varNACounts >= 19000          # set those variables with NAs to TRUE
goodTrainingData <- training[!badVars]   # Remove those variables with NAs from the training data
sum(is.na(cleanTrainingdata))            # check good training data has no NAs
dim(goodTrainingdata)
dim(goodTrainingData)
str(testing)
varNACounts
dim(goodTrainingData)
dim(goodTestingData)
dim(goodTestingData)
varNACounts <- colSums(is.na(testing))  # find out which variables have NAs (i.e colSums not equal to 0)
badVars <- varNACounts >= 20            # set those variables with NAs to TRUE
goodTestingData <- testing[!badVars]    # Remove those variables with NAs from the testing data
sum(is.na(goodTestingData))             # check good testing data has no NAs
dim(goodTestingData)
str(goodTestingData)
str(goodTestingData$classe)
goodTestingData$classe
str(goodTrainingData$classe)
summary(goodTrainingData$classe)
str(goodTestingData$classe)
varNACounts
str(goodTestingData)
str(goodTrainingData)
str(goodTestingData)
str(testing)
names(testing)
str(testing$classe)
str(training$classe)
str(testing$classe)
summary(goodTrainingdata$classe)
source('~/.active-rstudio-document', echo=TRUE)
str(goodTrainingData$classe)
counts <- table(goodTrainingData$classe)
barplot(counts, col=c("red", "green", "yellow", "blue", "orange"), main = "`classe` frequency plot", xlab = "Types of Weight Lifting Exercices")
counts <- table(goodTrainingData$classe)
barplot(counts, col=c("red", "yellow", "green", "blue", "purple"), main = "`classe` Distribution", xlab = "Types of `classe`")
counts
library (caret)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
str(goodTrainingData)
str(goodTestingData)
source('~/.active-rstudio-document', echo=TRUE)
